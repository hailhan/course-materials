{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7 Exercise 2 - EDA & Spark SQL in PySpark\n",
    "\n",
    "First configure our PySpark environment below, and then let's load the data from S3 into our Spark session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.pyspark.python\": \"python3\",\n",
    "        \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "        \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "        \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load the NOAA Global Historical Climatology Network (GHCN) Daily Weather Data. Documentation of the dataset: https://docs.opendata.aws/noaa-ghcn-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1714068429575_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-11-92.ec2.internal:20888/proxy/application_1714068429575_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-1-64.ec2.internal:8042/node/containerlogs/container_1714068429575_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.csv('s3://noaa-ghcn-pds/csv/by_year/2024.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[ID: string, DATE: string, ELEMENT: string, DATA_VALUE: string, M_FLAG: string, Q_FLAG: string, S_FLAG: string, OBS_TIME: string]"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- ELEMENT: string (nullable = true)\n",
      " |-- DATA_VALUE: string (nullable = true)\n",
      " |-- M_FLAG: string (nullable = true)\n",
      " |-- Q_FLAG: string (nullable = true)\n",
      " |-- S_FLAG: string (nullable = true)\n",
      " |-- OBS_TIME: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9616274"
     ]
    }
   ],
   "source": [
    "df.count() # return total count of rows in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that Spark DataFrames are built off of RDDs, we can still use methods like `take` to make small amounts of our data visible as list (we almost will never want to `collect` our data when working with big data, though; **ask**: Why?):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL also includes a `show` method that makes this a bit prettier, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "|         ID|    DATE|ELEMENT|DATA_VALUE|M_FLAG|Q_FLAG|S_FLAG|OBS_TIME|\n",
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "|AE000041196|20240101|   TMAX|       278|  null|  null|     S|    null|\n",
      "|AE000041196|20240101|   TMIN|       182|  null|  null|     S|    null|\n",
      "|AE000041196|20240101|   PRCP|         0|     D|  null|     S|    null|\n",
      "|AE000041196|20240101|   TAVG|       236|     H|  null|     S|    null|\n",
      "|AEM00041194|20240101|   TMAX|       277|  null|  null|     S|    null|\n",
      "+-----------+--------+-------+----------+------+------+------+--------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert column types\n",
    "df = df.withColumn(\"DATE\", F.col(\"DATE\").cast(\"int\"))\n",
    "df = df.withColumn(\"DATA_VALUE\", F.col(\"DATA_VALUE\").cast(\"double\"))\n",
    "# convert unit of temperature\n",
    "df = df.withColumn(\"DATA_VALUE\", F.col(\"DATA_VALUE\") / 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following 2 tasks, you can choose to complete using SQL queries or built-in Spark functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 1: \n",
    "Print out the date and maximum temperature from the DataFrame (ELEMENT is \"TMAX\") for each date, and order by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|    DATE|MaxTemperature|\n",
      "+--------+--------------+\n",
      "|20240101|          45.0|\n",
      "|20240102|          45.5|\n",
      "|20240103|          42.3|\n",
      "|20240104|          41.6|\n",
      "|20240105|          42.7|\n",
      "|20240106|          42.4|\n",
      "|20240107|          43.0|\n",
      "|20240108|          47.8|\n",
      "|20240109|          43.9|\n",
      "|20240110|          44.3|\n",
      "|20240111|          45.0|\n",
      "|20240112|          43.0|\n",
      "|20240113|          44.6|\n",
      "|20240114|          43.1|\n",
      "|20240115|          43.7|\n",
      "|20240116|          43.7|\n",
      "|20240117|          44.0|\n",
      "|20240118|          42.0|\n",
      "|20240119|          44.4|\n",
      "|20240120|          46.2|\n",
      "+--------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"weather\")\n",
    "query = \"\"\"\n",
    "            SELECT DATE, MAX(DATA_VALUE) as MaxTemperature\n",
    "            FROM weather\n",
    "            WHERE ELEMENT = 'TMAX'\n",
    "            GROUP BY DATE\n",
    "            ORDER BY DATE\n",
    "        \"\"\"\n",
    "max_temperatures = spark.sql(query)\n",
    "max_temperatures.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 2: Add another condition to filter out temperature lower than 47 degrees Celsius (note the unit of temperature in the data is tenths of degrees Celsius), and change the order to be by max temperature in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|    DATE|MaxTemperature|\n",
      "+--------+--------------+\n",
      "|20240314|         202.2|\n",
      "|20240310|          67.2|\n",
      "|20240304|          52.8|\n",
      "|20240417|          50.8|\n",
      "|20240324|          50.0|\n",
      "|20240218|          49.3|\n",
      "|20240403|          48.5|\n",
      "|20240108|          47.8|\n",
      "|20240219|          47.7|\n",
      "|20240311|          47.2|\n",
      "+--------+--------------+"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"weather\")\n",
    "query = \"\"\"\n",
    "            SELECT DATE, MAX(DATA_VALUE) as MaxTemperature\n",
    "            FROM weather\n",
    "            WHERE ELEMENT = 'TMAX'\n",
    "            GROUP BY DATE\n",
    "            HAVING MAX(DATA_VALUE) >= 47\n",
    "            ORDER BY MaxTemperature DESC\n",
    "        \"\"\"\n",
    "max_temperatures = spark.sql(query)\n",
    "max_temperatures.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use built-in methods and functions from Spark SQL to do the same thing on our Spark DataFrame directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|    DATE|MaxTemperature|\n",
      "+--------+--------------+\n",
      "|20240101|          45.0|\n",
      "|20240102|          45.5|\n",
      "|20240103|          42.3|\n",
      "|20240104|          41.6|\n",
      "|20240105|          42.7|\n",
      "|20240106|          42.4|\n",
      "|20240107|          43.0|\n",
      "|20240108|          47.8|\n",
      "|20240109|          43.9|\n",
      "|20240110|          44.3|\n",
      "|20240111|          45.0|\n",
      "|20240112|          43.0|\n",
      "|20240113|          44.6|\n",
      "|20240114|          43.1|\n",
      "|20240115|          43.7|\n",
      "|20240116|          43.7|\n",
      "|20240117|          44.0|\n",
      "|20240118|          42.0|\n",
      "|20240119|          44.4|\n",
      "|20240120|          46.2|\n",
      "+--------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "max_temperatures = (df\n",
    "                    .filter(F.col(\"ELEMENT\") == \"TMAX\")  \n",
    "                    .groupBy(\"DATE\") \n",
    "                    .agg(F.max(\"DATA_VALUE\").alias(\"MaxTemperature\")) \n",
    "                    .orderBy(\"DATE\"))\n",
    "max_temperatures.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|    DATE|MaxTemperature|\n",
      "+--------+--------------+\n",
      "|20240314|         202.2|\n",
      "|20240310|          67.2|\n",
      "|20240304|          52.8|\n",
      "|20240417|          50.8|\n",
      "|20240324|          50.0|\n",
      "|20240218|          49.3|\n",
      "|20240403|          48.5|\n",
      "|20240108|          47.8|\n",
      "|20240219|          47.7|\n",
      "|20240311|          47.2|\n",
      "+--------+--------------+"
     ]
    }
   ],
   "source": [
    "max_temperatures = (df\n",
    "                    .filter(F.col(\"ELEMENT\") == \"TMAX\") \n",
    "                    .groupBy(\"DATE\") \n",
    "                    .agg(F.max(\"DATA_VALUE\").alias(\"MaxTemperature\")) \n",
    "                    .filter(F.col(\"MaxTemperature\") >= 47) \n",
    "                    .orderBy(F.col(\"MaxTemperature\").desc()))\n",
    "\n",
    "max_temperatures.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
